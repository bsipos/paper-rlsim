#!/usr/bin/env python

VERSION="1.0"

import      matplotlib
matplotlib.use('Agg')
import      sys
import      os
import      numpy       as      np
from        matplotlib  import  pyplot  as plt
import      argparse
from        matplotlib.backends.backend_pdf import  PdfPages
import      cPickle
from        collections import defaultdict
import      matplotlib.cm   as cmx
import      matplotlib.colors   as colors

##
## Functions and classes:
##

def parse_arguments():
    """ Parse arguments """
    parser = argparse.ArgumentParser(description='Collate the results from different datasets on a single plot(version %s).' % VERSION)
    parser.add_argument('-c', metavar='cov_pickles', type=str, nargs='+', help='Pickles generated by cov_cmp.', required=False)
    parser.add_argument('-p', metavar='pb_pickles',type=str, nargs='+', help='Pickles generated by pb_plot.', required=False)
    parser.add_argument('-k', metavar='kmer_pickles',type=str, nargs='+', help='Pickles generated by kmer_freqs.', required=False)
    parser.add_argument('-bc', metavar='base_cov_pickles', type=str, nargs='+', help='Pickles for correlation baseline from cov_cmp.', required=False)
    parser.add_argument('-bp', metavar='base_pb_pickles', type=str, nargs='+', help='Pickles for GC content/PB baseline from meta_pb_cmp.', required=False)
    parser.add_argument('-l', metavar='labels',type=str, help='Dataset labels file.', required=False)
    parser.add_argument('-r', metavar='pdf', default="global_report.pdf",type=str,  help='Report PDF.', required=False)
    args                             = parser.parse_args()
    if args.c is None or args.p is None:
        print "Not enough input!"
        sys.exit(1)
    return args

def double_min(a, b):
    return min(min(a), min(b))

def double_max(a, b):
    return max(max(a), max(b))

def load_labels(f):
    lab = { }
    fh  = open(f)
    for l in fh:
        t       = l.strip().split("\t")
        k       = t[1].strip()
        lab[k]  = ' - '.join(t)
    return lab

def add_label(k, lab):
    if k in lab:
        return lab[k]
    return k

class Report:
    """ Class for plotting reports """
    def __init__(self, pdf):
        self.pdf    = pdf
        self.pages  = PdfPages(pdf)

    def plot_v(self, v, bv={}, title="",xlab="",ylab=""):
        """ Plot full and flat model rho values """
        fig         = plt.figure()
        ms          = 6 
        alpha       = 0.7
        minx, maxx  = -0.8, 0.8 
        delta       = 0.05

        # Initialise colormap.
        jet = cm = plt.get_cmap('jet') 
        cNorm  = colors.Normalize(vmin=0, vmax=len(v['ds']))
        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)

        # Initialise subplots:
        ax1 = plt.subplot(221)
        ax2 = plt.subplot(222)
        ax3 = plt.subplot(223)
        xpos = np.linspace(minx+0.05, maxx-0.05, len(v['ds']))

        # Plot GC content rho values:

        # Set x axis properties:
        xax1 = ax1.get_xaxis()
        xax1.set_ticks([])
        xax1.set_label_text("Fragment GC content distribution")
        xax1.set_view_interval(minx-delta, maxx+delta)
        # Set y axis properties:
        yax1 = ax1.get_yaxis()
        yax1.set_view_interval(double_min(v['gc'],v['gc_f'])-delta, double_max(v['gc'],v['gc_f']))

        for i in xrange(len(v['ds'])):
            cls    = scalarMap.to_rgba(i)
            pos    = [xpos[i]]
            # Plot full model rho value markers:
            points = np.array([ v['gc'][i] ])
            ax1.plot(pos, points, '.', ms=ms, marker='^', color=cls, alpha=alpha, label=v['ds'][i]) 
            # Plot flat model rho value markers:
            points_f = np.array([ v['gc_f'][i] ])
            ax1.plot(pos, points_f, '.', ms=ms, marker='s', color=cls, alpha=alpha, label=v['ds'][i])
            # Connect markers with a line:
            ax1.vlines(x=pos, ymin=[v['gc_f'][i]], ymax=[v['gc'][i]], color=cls, alpha=alpha)

        # Add baseline GC correlations
        ax1.hlines([np.mean(bv['gc'])], minx-delta, maxx+delta, label="Baseline", color=cls, alpha=alpha)

        # Plot sequence bias rho values:

        # Set x axis properties:
        xax2 = ax2.get_xaxis()
        xax2.set_ticks([])
        xax2.set_label_text("Sequence bias")
        xax2.set_view_interval(minx-delta, maxx+delta)
        # Set y axis properties:
        yax2 = ax3.get_yaxis()
        yax2.set_label_text("Mean Spearman's rho")
        yax2.set_view_interval(double_min(v['counts'],v['counts_f'])-delta, double_max(v['counts'],v['counts_f']))

        for i in xrange(len(v['ds'])):
            cls    = scalarMap.to_rgba(i)
            pos    = [xpos[i]]
            # Plot full model rho value markers:
            points = np.array([ v['counts'][i] ])
            ax2.plot(pos, points, '.', ms=ms, marker='^', color=cls, alpha=alpha, label=v['ds'][i]) 
            # Plot flat model rho value markers:
            points_f = np.array([ v['counts_f'][i] ])
            ax2.plot(pos, points_f, '.', ms=ms, marker='s', color=cls, alpha=alpha, label=v['ds'][i]) 
            # Connect markers with a line:
            ax2.vlines(x=pos, ymin=[v['counts_f'][i]], ymax=[v['counts'][i]], color=cls, alpha=alpha)

        # Add the baseline sequence bias
        ax2.hlines([np.mean(bv['counts'])], minx-delta, maxx+delta, color=cls, alpha=alpha)

        # Plot expression level rho values:

        # Set x axis properties:
        xax3 = ax3.get_xaxis()
        xax3.set_ticks([])
        xax3.set_label_text("Nonzero expression levels")
        xax3.set_view_interval(minx-delta, maxx+delta)
        # Set y axis properties:
        yax3 = ax3.get_yaxis()
        yax3.set_label_text("Spearman's rho")
        yax3.set_view_interval(double_min(v['el'],v['el_f'])-delta, double_max(v['el'],v['el_f']))

        for i in xrange(len(v['ds'])):
            cls    = scalarMap.to_rgba(i)
            pos    = [xpos[i]]
            # Plot full model rho value markers:
            points = np.array([ v['el'][i] ])
            ax3.plot(pos, points, '.', ms=ms, marker='^', color=cls, alpha=alpha, label=v['ds'][i]) 
            # Plot flat model rho value markers:
            points_f = np.array([ v['el_f'][i] ])
            ax3.plot(pos, points_f, '.', ms=ms, marker='s', color=cls, alpha=alpha) 
            # Connect markers with a line:
            ax3.vlines(x=pos, ymin=[v['el_f'][i]], ymax=[v['el'][i]], color=cls, alpha=alpha)

        # Add the baseline correlations
        ax3.hlines([np.mean(bv['el'])], minx-delta, maxx+delta, color=cls, alpha=alpha)

        # Plot legend:
        ax3.legend(loc=2, bbox_to_anchor=(1.01, 1), prop={'size':7},numpoints=1, markerscale=0.6)

        self.pages.savefig(fig)
        plt.clf()
        plt.close(fig)

    def close(self):
        self.pages.close()

def unpickle(f):
    """ Load data from pickle file """
    fh     = open(f, "r")
    pickle = cPickle.Unpickler( fh )
    tmp = pickle.load()
    return tmp

def parse_name(n):
    """ Parse pickle path """
    tmp = n.split(os.sep)
    return (tmp[-3], tmp[-1])

def load_cov(cf, d):
    """ Load rhos from the cov_cmp pickle """
    for n in cf:
        s,f                 = parse_name(n)
        t                   = unpickle(n)
        d[s]['d_el_rho']    = t['d_el_rho']
        d[s]['el_rho']      = t['el_rho']
        d[s]['el_rho_flat'] = t['el_rho_flat']

def load_base(cf, d):
    """ Load rhos from the cov_cmp pickle """
    for n in cf:
        s,f                 = parse_name(n)
        t                   = unpickle(n)
        d[s]['el_rho']      = t['el_rho']

def load_pb(cp, d):
    """ Load rhos from the pb_plot pickle """
    for n in cp:
        s,f = parse_name(n)
        t   = unpickle(n)
        if not f.endswith('flat.pk'):
            d[s]['gc_rho'] = t['gc_rho']
            d[s]['counts_rho'] = t['counts_rho']
        else:
            d[s]['gc_rho_flat'] = t['gc_rho']
            d[s]['counts_rho_flat'] = t['counts_rho']

def reduce_pb(d):
    """ Calculate gc and counts rho improvements """
    for t in d.values():
        if 'gc_rho' in t and 'gc_rho_flat' in t:
            t['d_gc_rho'] = t['gc_rho'] - t['gc_rho_flat']
        if 'counts_rho' in t and 'counts_rho_flat' in t:
            t['d_counts_rho'] = t['counts_rho'] - t['counts_rho_flat']

def load_kmer_freqs(kf, d):
    """ Load kmer frequency correlations """
    for n in kf:
        s, f = parse_name(n)
        t = unpickle(n)
        if not f.endswith('flat.pk'):
            d[s]['kmer_freqs_rho'] = t['kmer_freqs_rho']
        else:
            d[s]['kmer_freqs_rho_flat'] = t['kmer_freqs_rho']

def load_mean_gc(mf, d):
    """ Load mean GC correlations """
    for n in mf:
        s, f = parse_name(n)
        t = unpickle(n)
        if not f.endswith('flat.pk'):
            d[s]['mean_gc_rho'] = t['mean_gc_rho']
        else:
            d[s]['mean_gc_rho_flat'] = t['mean_gc_rho']    

def build_vecs(d, lab):
    """ Build dataset and rho vectors """
    lds, d_el, d_gc, d_counts = [], [], [], []
    kmer_freqs, kmer_freqs_f, mean_gc, mean_gc_f = [], [], [], []
    el, el_f, gc, gc_f, counts, counts_f = [], [], [], [], [], []
    ds  = sorted(d.keys(), key=lambda x: add_label(x,lab))

    for n in ds:
        d_el.append(d[n]['d_el_rho'])
        d_gc.append(d[n]['d_gc_rho'])
        d_counts.append(d[n]['d_counts_rho'])
        el.append(d[n]['el_rho'])
        el_f.append(d[n]['el_rho_flat'])
        gc.append(d[n]['gc_rho'])
        gc_f.append(d[n]['gc_rho_flat'])
        kmer_freqs.append(d[n]['kmer_freqs_rho'])
        kmer_freqs_f.append(d[n]['kmer_freqs_rho_flat'])
        mean_gc.append(d[n]['mean_gc_rho'])
        mean_gc_f.append(d[n]['mean_gc_rho_flat'])
        counts.append(d[n]['counts_rho'])
        counts_f.append(d[n]['counts_rho_flat'])
        lds.append(add_label(n,lab))
    return {
        'ds': lds,
        'd_el': d_el,
        'd_gc': d_gc,
        'd_counts': d_counts,
        'el': el,
        'el_f': el_f,
        'gc': gc,
        'gc_f': gc_f,
        'kmer_freqs': kmer_freqs,
        'kmer_freqs_f': kmer_freqs_f,
        'mean_gc': mean_gc,
        'mean_gc_f': mean_gc_f,
        'counts': counts,
        'counts_f': counts_f,
    }

args        = parse_arguments()
R           = Report(args.r)

cf          = args.c or [] # cov. correlations
pf          = args.p or [] # pbplot correlations

bcf         = args.bc or [] # coverage cor. baselines
bpf         = args.bp or [] # pbplot baselines

d           = defaultdict(lambda: defaultdict(float))
bd          = defaultdict(lambda: defaultdict(float))
lab         = None
if args.l is not None:
    lab =  load_labels(args.l)

load_cov(cf, d)
load_pb(pf, d)

load_base(bcf, bd)
load_pb(bpf, bd)

reduce_pb(d)
v = build_vecs(d, lab)
bv = build_vecs(bd, lab)

R.plot_v(v, bv, title="",xlab="",ylab="")
R.close()
